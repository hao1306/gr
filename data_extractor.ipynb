{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 32.054 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 8.2 seconds.\n",
      "======\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-test...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "0 instance,\n",
      "12 sensor,\n",
      "1800 calibrated_sensor,\n",
      "462901 ego_pose,\n",
      "15 log,\n",
      "150 scene,\n",
      "6008 sample,\n",
      "462901 sample_data,\n",
      "0 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 3.155 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.9 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot='dataset/nuscenes/trian', verbose=True)\n",
    "nusc_test = NuScenes(version='v1.0-test', dataroot='dataset/nuscenes/test', verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing of scenes: 100%|██████████| 850/850 [00:01<00:00, 466.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to dataset/nuscenes/trian/data_one_camera.csv\n",
      "Data has been written to dataset/nuscenes/trian/data_all_camera.csv\n",
      "l1 (10954, 36) l2 (10954, 56)\n"
     ]
    }
   ],
   "source": [
    "length01 = len(nusc.scene)\n",
    "# length01 = 2\n",
    "sensor1 = 'CAM_FRONT'\n",
    "sensor2 = 'CAM_BACK'\n",
    "sensor3 = 'CAM_BACK_LEFT'\n",
    "sensor4 = 'CAM_BACK_RIGHT'\n",
    "sensor5 = 'CAM_FRONT_RIGHT'\n",
    "sensor6 = 'CAM_FRONT_LEFT'\n",
    "csv_data_singlecamera = [] # store the data for training, only one camera is used\n",
    "csv_data_allcamera = [] # store data from all cameras\n",
    "filepath = 'dataset/nuscenes/trian/'\n",
    "\n",
    "# extract img path and the xy coordinate of samples in every scene\n",
    "for i in tqdm(range(length01), desc=\"processing of scenes\"):\n",
    "\n",
    "    time.sleep(0.001)\n",
    "    my_scene = nusc.scene[i]\n",
    "    num_sample = my_scene['nbr_samples']\n",
    "    sample_token = None\n",
    "    sample_token_next = None\n",
    "    csv_data_scene = [] # store data of single scene\n",
    "\n",
    "    # extract data from each sample\n",
    "    for j in range(num_sample):\n",
    "        if j == 0:\n",
    "            sample_token = my_scene['first_sample_token']\n",
    "            my_sample = nusc.get('sample', sample_token)\n",
    "            sample_token_next = my_sample['next']\n",
    "        elif j == (num_sample - 1):\n",
    "            sample_token = my_scene['last_sample_token']\n",
    "            my_sample = nusc.get('sample', sample_token)\n",
    "        else:\n",
    "            sample_token = sample_token_next\n",
    "            my_sample = nusc.get('sample', sample_token)\n",
    "            sample_token_next = my_sample['next']\n",
    "        \n",
    "        # get the data of different sensor (camera in different positions)\n",
    "        cam_data_01 = nusc.get('sample_data', my_sample['data'][sensor1]) # 'CAM_FRONT'\n",
    "        cam_data_02 = nusc.get('sample_data', my_sample['data'][sensor2]) # 'CAM_BACK'\n",
    "        cam_data_03 = nusc.get('sample_data', my_sample['data'][sensor3]) # 'CAM_BACK_LEFT'\n",
    "        cam_data_04 = nusc.get('sample_data', my_sample['data'][sensor4]) # 'CAM_BACK_RIGHT'\n",
    "        cam_data_05 = nusc.get('sample_data', my_sample['data'][sensor5]) # 'CAM_FRONT_RIGHT'\n",
    "        cam_data_06 = nusc.get('sample_data', my_sample['data'][sensor6]) # 'CAM_FRONT_LEFT'\n",
    "        img_xy = []\n",
    "        img_xy.append(cam_data_01['filename'])\n",
    "        img_xy.append(cam_data_02['filename'])\n",
    "        img_xy.append(cam_data_03['filename'])\n",
    "        img_xy.append(cam_data_04['filename'])\n",
    "        img_xy.append(cam_data_05['filename'])\n",
    "        img_xy.append(cam_data_06['filename'])\n",
    "        ego_pose_token = cam_data_01['ego_pose_token']\n",
    "        ego_pose = nusc.get('ego_pose', ego_pose_token)['translation']\n",
    "        img_xy.append(ego_pose[0])\n",
    "        img_xy.append(ego_pose[1])\n",
    "\n",
    "        # size of img_xy: 8*1 (6 img path + x and y coordinate), it collects all needed data in one sample\n",
    "        csv_data_scene.append(img_xy) # shape: num_sample * 8\n",
    "\n",
    "    # print(np.shape(csv_data_scene))\n",
    "\n",
    "    # deal with all extracted data in one scene\n",
    "    # 4 imges and their corresponding xy coordinates for input and 12 xy coordinates as prediction\n",
    "    num_group = (num_sample - 16) // 2 + 1\n",
    "    \n",
    "    for t in range(num_group):\n",
    "        \n",
    "        m = t * 2\n",
    "        data_group_onecamera = []\n",
    "        data_group_allcamera = []\n",
    "        \n",
    "        # for each group for single camera, data is (img path * 1 + x + y) * 4 + (x + y) * 12\n",
    "        # for each group for all cameras, data id (img path * 6 + x + y) * 4 + (x + y) * 12\n",
    "        for n in range(16):\n",
    "            if n < 4:\n",
    "                # data_group_onecamera += csv_data_scene[m + n][0] + csv_data_scene[m + n][-2:]\n",
    "                data_group_onecamera.append(csv_data_scene[m + n][0])\n",
    "                data_group_onecamera += csv_data_scene[m + n][-2:]\n",
    "                data_group_allcamera += csv_data_scene[m + n][0:]\n",
    "            else:\n",
    "                data_group_onecamera += csv_data_scene[m + n][-2:]\n",
    "                data_group_allcamera += csv_data_scene[m + n][-2:]\n",
    "        \n",
    "        # print('data_group_onecamera', np.shape(data_group_onecamera))\n",
    "\n",
    "        csv_data_singlecamera.append(data_group_onecamera)\n",
    "        csv_data_allcamera.append(data_group_allcamera)\n",
    "\n",
    "# create csv files to store the data from one camera and data from all cameras\n",
    "\n",
    "# CSV file path\n",
    "csv_file1 = \"dataset/nuscenes/trian/data_one_camera.csv\"\n",
    "csv_file2 = \"dataset/nuscenes/trian/data_all_camera.csv\"\n",
    "\n",
    "# write the data in csv files\n",
    "with open(csv_file1, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(csv_data_singlecamera)\n",
    "\n",
    "with open(csv_file2, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(csv_data_allcamera)\n",
    "\n",
    "print(f\"Data has been written to {csv_file1}\")\n",
    "print(f\"Data has been written to {csv_file2}\")\n",
    "\n",
    "l1 = np.array(csv_data_singlecamera)\n",
    "l2 = np.array(csv_data_allcamera)\n",
    "print('l1', l1.shape, 'l2', l2.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing of scenes: 100%|██████████| 150/150 [00:00<00:00, 491.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to dataset/nuscenes/test/data_one_camera_test.csv\n",
      "Data has been written to dataset/nuscenes/test/data_all_camera_test.csv\n",
      "l1 (1934, 36) l2 (1934, 56)\n"
     ]
    }
   ],
   "source": [
    "length01 = len(nusc_test.scene)\n",
    "# length01 = 2\n",
    "sensor1 = 'CAM_FRONT'\n",
    "sensor2 = 'CAM_BACK'\n",
    "sensor3 = 'CAM_BACK_LEFT'\n",
    "sensor4 = 'CAM_BACK_RIGHT'\n",
    "sensor5 = 'CAM_FRONT_RIGHT'\n",
    "sensor6 = 'CAM_FRONT_LEFT'\n",
    "csv_data_singlecamera = [] # store the data for training, only one camera is used\n",
    "csv_data_allcamera = [] # store data from all cameras\n",
    "\n",
    "# extract img path and the xy coordinate of samples in every scene\n",
    "for i in tqdm(range(length01), desc=\"processing of scenes\"):\n",
    "\n",
    "    time.sleep(0.001)\n",
    "    my_scene = nusc_test.scene[i]\n",
    "    num_sample = my_scene['nbr_samples']\n",
    "    sample_token = None\n",
    "    sample_token_next = None\n",
    "    csv_data_scene = [] # store data of single scene\n",
    "\n",
    "    # extract data from each sample\n",
    "    for j in range(num_sample):\n",
    "        if j == 0:\n",
    "            sample_token = my_scene['first_sample_token']\n",
    "            my_sample = nusc_test.get('sample', sample_token)\n",
    "            sample_token_next = my_sample['next']\n",
    "        elif j == (num_sample - 1):\n",
    "            sample_token = my_scene['last_sample_token']\n",
    "            my_sample = nusc_test.get('sample', sample_token)\n",
    "        else:\n",
    "            sample_token = sample_token_next\n",
    "            my_sample = nusc_test.get('sample', sample_token)\n",
    "            sample_token_next = my_sample['next']\n",
    "        \n",
    "        # get the data of different sensor (camera in different positions)\n",
    "        cam_data_01 = nusc_test.get('sample_data', my_sample['data'][sensor1]) # 'CAM_FRONT'\n",
    "        cam_data_02 = nusc_test.get('sample_data', my_sample['data'][sensor2]) # 'CAM_BACK'\n",
    "        cam_data_03 = nusc_test.get('sample_data', my_sample['data'][sensor3]) # 'CAM_BACK_LEFT'\n",
    "        cam_data_04 = nusc_test.get('sample_data', my_sample['data'][sensor4]) # 'CAM_BACK_RIGHT'\n",
    "        cam_data_05 = nusc_test.get('sample_data', my_sample['data'][sensor5]) # 'CAM_FRONT_RIGHT'\n",
    "        cam_data_06 = nusc_test.get('sample_data', my_sample['data'][sensor6]) # 'CAM_FRONT_LEFT'\n",
    "        img_xy = []\n",
    "        img_xy.append(cam_data_01['filename'])\n",
    "        img_xy.append(cam_data_02['filename'])\n",
    "        img_xy.append(cam_data_03['filename'])\n",
    "        img_xy.append(cam_data_04['filename'])\n",
    "        img_xy.append(cam_data_05['filename'])\n",
    "        img_xy.append(cam_data_06['filename'])\n",
    "        ego_pose_token = cam_data_01['ego_pose_token']\n",
    "        ego_pose = nusc_test.get('ego_pose', ego_pose_token)['translation']\n",
    "        img_xy.append(ego_pose[0])\n",
    "        img_xy.append(ego_pose[1])\n",
    "\n",
    "        # size of img_xy: 8*1 (6 img path + x and y coordinate), it collects all needed data in one sample\n",
    "        csv_data_scene.append(img_xy)\n",
    "\n",
    "    # deal with all extracted data in one scene\n",
    "    # 4 imges and their corresponding xy coordinates for input and 12 xy coordinates as prediction\n",
    "    num_group = (num_sample - 16) // 2 + 1\n",
    "    \n",
    "    for t in range(num_group):\n",
    "        m = t * 2\n",
    "        data_group_onecamera = []\n",
    "        data_group_allcamera = []\n",
    "        \n",
    "        # for each group for single camera, data is (img path * 1 + x + y) * 4 + (x + y) * 12\n",
    "        # for each group for all cameras, data id (img path * 6 + x + y) * 4 + (x + y) * 12\n",
    "        for n in range(16):\n",
    "            if n < 4:\n",
    "                # data_group_onecamera += csv_data_scene[m + n][0] + csv_data_scene[m + n][-2:]\n",
    "                data_group_onecamera.append(csv_data_scene[m + n][0])\n",
    "                data_group_onecamera += csv_data_scene[m + n][-2:]\n",
    "                data_group_allcamera += csv_data_scene[m + n][0:]\n",
    "            else:\n",
    "                data_group_onecamera += csv_data_scene[m + n][-2:]\n",
    "                data_group_allcamera += csv_data_scene[m + n][-2:]\n",
    "\n",
    "        csv_data_singlecamera.append(data_group_onecamera)\n",
    "        csv_data_allcamera.append(data_group_allcamera)\n",
    "\n",
    "# create csv files to store the data from one camera and data from all cameras\n",
    "\n",
    "# CSV file path\n",
    "csv_file1 = \"dataset/nuscenes/test/data_one_camera_test.csv\"\n",
    "csv_file2 = \"dataset/nuscenes/test/data_all_camera_test.csv\"\n",
    "\n",
    "# write the data in csv files\n",
    "with open(csv_file1, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(csv_data_singlecamera)\n",
    "\n",
    "with open(csv_file2, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(csv_data_allcamera)\n",
    "\n",
    "print(f\"Data has been written to {csv_file1}\")\n",
    "print(f\"Data has been written to {csv_file2}\")\n",
    "\n",
    "l1 = np.array(csv_data_singlecamera)\n",
    "l2 = np.array(csv_data_allcamera)\n",
    "print('l1', l1.shape, 'l2', l2.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/nuscenes/trian/samples/CAM_FRONT/n015-2018-07-18-11-07-57+0800__CAM_FRONT__1531883530412470.jpg',\n",
       " 1010.1102882349232,\n",
       " 610.6567106479714,\n",
       " 1010.1196021097104,\n",
       " 610.7194357591594]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_scene = nusc.scene[0]\n",
    "example_token = example_scene['first_sample_token']\n",
    "example_sample = nusc.get('sample', example_token)\n",
    "cam_data = nusc.get('sample_data', example_sample['data']['CAM_FRONT'])\n",
    "cam_data2 = nusc.get('sample_data', example_sample['data']['CAM_BACK_RIGHT'])\n",
    "imgpath = []\n",
    "imgpath.append('dataset/nuscenes/trian/' + cam_data['filename'])\n",
    "ego_pose_token1 = cam_data['ego_pose_token']\n",
    "ego_pose = nusc.get('ego_pose', ego_pose_token1)['translation']\n",
    "ego_pose_token2 = cam_data2['ego_pose_token']\n",
    "ego_pose2 = nusc.get('ego_pose', ego_pose_token2)['translation']\n",
    "imgpath.append(ego_pose[0])\n",
    "imgpath.append(ego_pose[1])\n",
    "imgpath.append(ego_pose2[0])\n",
    "imgpath.append(ego_pose2[1])\n",
    "imgpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imgpath[0])\n",
    "cv2.imshow('Image' ,img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to example.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# 数据\n",
    "data = [\n",
    "    [\"Name\", \"Age\", \"City\"],\n",
    "    [\"Alice\", 25, \"New York\"],\n",
    "    [\"Bob\", 30, \"Los Angeles\"],\n",
    "    [\"Charlie\", 22, \"Chicago\"]\n",
    "]\n",
    "\n",
    "# CSV文件路径\n",
    "csv_file = \"example.csv\"\n",
    "\n",
    "# 写入数据到CSV文件\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data has been written to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'Age', 'City']\n",
      "['Alice', '25', 'New York']\n",
      "['Bob', '30', 'Los Angeles']\n",
      "['Charlie', '22', 'Chicago']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# CSV文件路径\n",
    "csv_file = \"example.csv\"  # 你需要将文件路径替换为你的CSV文件路径\n",
    "\n",
    "# 创建一个空列表，用于存储每一行的数据\n",
    "data_list = []\n",
    "\n",
    "# 逐行读取CSV文件并存储为列表\n",
    "with open(csv_file, mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        data_list.append(row)\n",
    "\n",
    "# 打印每一行的数据\n",
    "for row in data_list:\n",
    "    print(row)\n",
    "np.shape(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': 'e3d495d4ac534d54b321f50006683844',\n",
       " 'sample_token': 'ca9a282c9e77460f8360f564131a8af5',\n",
       " 'ego_pose_token': 'e3d495d4ac534d54b321f50006683844',\n",
       " 'calibrated_sensor_token': '1d31c729b073425e8e0202c5c6e66ee1',\n",
       " 'timestamp': 1532402927612460,\n",
       " 'fileformat': 'jpg',\n",
       " 'is_key_frame': True,\n",
       " 'height': 900,\n",
       " 'width': 1600,\n",
       " 'filename': 'samples/CAM_FRONT/n015-2018-07-24-11-22-45+0800__CAM_FRONT__1532402927612460.jpg',\n",
       " 'prev': '',\n",
       " 'next': '68e8e98cf7b0487baa139df808641db7',\n",
       " 'sensor_modality': 'camera',\n",
       " 'channel': 'CAM_FRONT'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor = 'CAM_FRONT'\n",
    "cam_front_data_01 = nusc.get('sample_data', my_sample['data'][sensor])\n",
    "cam_front_data_02 = nusc.get('sample_data', my_sample_02['data'][sensor])\n",
    "cam_front_data_01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': '4b6870ae200c4b969b91c50a9737f712',\n",
       " 'sample_token': '39586f9d59004284a7114a68825e8eec',\n",
       " 'ego_pose_token': '4b6870ae200c4b969b91c50a9737f712',\n",
       " 'calibrated_sensor_token': '1d31c729b073425e8e0202c5c6e66ee1',\n",
       " 'timestamp': 1532402928112460,\n",
       " 'fileformat': 'jpg',\n",
       " 'is_key_frame': True,\n",
       " 'height': 900,\n",
       " 'width': 1600,\n",
       " 'filename': 'samples/CAM_FRONT/n015-2018-07-24-11-22-45+0800__CAM_FRONT__1532402928112460.jpg',\n",
       " 'prev': 'e92333479b9048c88c5db855621f4401',\n",
       " 'next': 'cb21f6eaada04b42a1b05d2c7a34e857',\n",
       " 'sensor_modality': 'camera',\n",
       " 'channel': 'CAM_FRONT'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_front_data_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = []\n",
    "ego_pose = []\n",
    "img_path.append(cam_front_data_01['filename'])\n",
    "img_path.append(cam_front_data_02['filename'])\n",
    "ego_pose.append(cam_front_data_01['ego_pose_token'])\n",
    "ego_pose.append(cam_front_data_02['ego_pose_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1.0-mini/samples/CAM_FRONT/n015-2018-07-24-11-22-45+0800__CAM_FRONT__1532402927612460.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "path = 'v1.0-mini/' + img_path[0]\n",
    "print(path)\n",
    "img = cv2.imread(path)\n",
    "cv2.imshow('Image' ,img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[411.4199861830012, 1181.197175631848, 0.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose01 = nusc.get('ego_pose', ego_pose[0])['translation']\n",
    "pose01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e3d495d4ac534d54b321f50006683844', '4b6870ae200c4b969b91c50a9737f712']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ego_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 'ichbindeinvater', 1, 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5]\n",
    "b = ['ichbindeinvater', 1, 2]\n",
    "c = []\n",
    "c += a + b\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
